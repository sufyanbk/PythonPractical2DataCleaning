{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0667e544",
   "metadata": {},
   "source": [
    "\n",
    "# DSE ↔ PROD Overlap — **Single Joined CSV (No Joins Needed)**\n",
    "\n",
    "This notebook expects **one CSV** at `utils/dataset.csv` (already joined) and computes:\n",
    "\n",
    "- Per‑row **alert flags** for DSE and PROD using per‑channel thresholds.\n",
    "- **Summaries by channel**: counts, alerts, fraud‑in‑alerts for DSE and PROD.\n",
    "- **Alert overlap** in the *same row*: intersection, DSE‑only (**PROD false negatives**), PROD‑only (**PROD false positives**), plus percentages.\n",
    "- **Fraud overlap within alerts** similarly framed.\n",
    "- **Score diagnostics for mismatches**: distributions and **margins vs thresholds**.\n",
    "- **Hour‑of‑day** distributions for intersections and mismatches.\n",
    "\n",
    "> Tip: If your channels/thresholds differ, edit the `CONFIG` cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb7101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================\n",
    "# CONFIG — paths & thresholds\n",
    "# ============================\n",
    "from pathlib import Path\n",
    "\n",
    "CONFIG = {\n",
    "    \"path\": {\n",
    "        # Primary path. We auto-fallback to `utils/dataset` (no extension) if needed.\n",
    "        \"csv\": \"utils/dataset.csv\"\n",
    "    },\n",
    "    # Column names present in the single joined CSV.\n",
    "    # If any are missing, the notebook will attempt reasonable fallbacks.\n",
    "    \"cols\": {\n",
    "        \"lifecycle_id\": \"lifecycle_id\",\n",
    "        \"channel\": \"channel\",                    # if absent, we'll synthesize 'ALL'\n",
    "        \"event_ts\": \"event_received_at\",         # parsed to hour\n",
    "        \"dse_raw_score\": \"dse_raw_score\",\n",
    "        \"dse_mt_score\": \"dse_mt_score\",\n",
    "        \"prod_raw_score\": \"raw_score\",           # aka shadow / prod raw score\n",
    "        \"prod_mt_score\": \"mt_score\",\n",
    "        # First match found from this list will be used as boolean fraud label\n",
    "        \"fraud_label_candidates\": [\n",
    "            \"fraud_label\",\n",
    "            \"is_fraud\",\n",
    "            \"fraud\",\n",
    "            \"fraud_label_true_scored\",\n",
    "            \"fraud_label_true\",\n",
    "            \"label_fraud\"\n",
    "        ]\n",
    "    },\n",
    "    # If your scores are 0–1 instead of 0–1000, enable scaling to 0–1000 thresholds.\n",
    "    \"scaling\": {\n",
    "        \"dse_raw_scale_x1000\": True,\n",
    "        \"dse_mt_scale_x1000\": True,\n",
    "        \"prod_raw_scale_x1000\": True,\n",
    "        \"prod_mt_scale_x1000\": True\n",
    "    },\n",
    "    # Per-channel thresholds (fill with your Looker values as needed).\n",
    "    # If a row's channel is unseen, we fall back to 'DEFAULT' if present; otherwise the first key.\n",
    "    \"thresholds\": {\n",
    "        \"DG\":  {\"RS\": 980, \"MT\": 765},\n",
    "        \"FD\":  {\"RS\": 980, \"MT\": 765},\n",
    "        \"CMB\": {\"RS\": 980, \"MT\": 765},\n",
    "        \"DEFAULT\": {\"RS\": 980, \"MT\": 765}\n",
    "    },\n",
    "    # Output directory for CSV exports\n",
    "    \"out_dir\": \"overlap_outputs\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedeb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======================\n",
    "# Imports & setup (pandas)\n",
    "# ======================\n",
    "import os, sys, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "os.makedirs(CONFIG[\"out_dir\"], exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Load the single CSV\n",
    "# =====================\n",
    "def _resolve_csv(path_str: str) -> Path:\n",
    "    p = Path(path_str)\n",
    "    if p.exists():\n",
    "        return p\n",
    "    # Fallback: path without extension\n",
    "    p2 = Path(str(p).rstrip(\".csv\"))\n",
    "    if p2.exists():\n",
    "        return p2\n",
    "    # Fallback: utils/dataset vs ./dataset\n",
    "    if not p.exists():\n",
    "        p3 = Path(\"utils\") / \"dataset.csv\"\n",
    "        if p3.exists():\n",
    "            return p3\n",
    "    return p\n",
    "\n",
    "csv_path = _resolve_csv(CONFIG[\"path\"][\"csv\"])\n",
    "if not csv_path.exists():\n",
    "    raise FileNotFoundError(f\"CSV not found at '{csv_path}'. Place your joined file at utils/dataset.csv\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"Loaded {len(df):,} rows from {csv_path}\")\n",
    "print(\"Columns:\", list(df.columns)[:40], (\"...\" if df.shape[1] > 40 else \"\"))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fcffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==================================================\n",
    "# Prep: ensure needed columns, fill fallbacks\n",
    "# ==================================================\n",
    "C = CONFIG[\"cols\"]\n",
    "\n",
    "# Channel\n",
    "if C[\"channel\"] not in df.columns:\n",
    "    df[\"channel\"] = \"ALL\"\n",
    "\n",
    "# Fraud label: pick first candidate present, coerce to bool\n",
    "fraud_col = None\n",
    "for cand in C[\"fraud_label_candidates\"]:\n",
    "    if cand in df.columns:\n",
    "        fraud_col = cand\n",
    "        break\n",
    "if fraud_col is None:\n",
    "    df[\"fraud_label\"] = False\n",
    "    fraud_col = \"fraud_label\"\n",
    "else:\n",
    "    # Robust cast to boolean (treat 1/'true'/'True' as True)\n",
    "    df[\"fraud_label\"] = df[fraud_col].astype(str).str.lower().isin([\"1\",\"true\",\"t\",\"yes\",\"y\"])\n",
    "    fraud_col = \"fraud_label\"\n",
    "\n",
    "# Event hour\n",
    "ts_col = C[\"event_ts\"]\n",
    "if ts_col in df.columns:\n",
    "    ts = pd.to_datetime(df[ts_col], errors=\"coerce\", utc=True)\n",
    "    # local hour isn't known; use UTC hour to keep consistent\n",
    "    df[\"hour\"] = ts.dt.hour\n",
    "else:\n",
    "    df[\"hour\"] = np.nan\n",
    "\n",
    "# Score scaling helpers\n",
    "def _scale_if_needed(series: pd.Series, scale_x1000: bool) -> pd.Series:\n",
    "    if scale_x1000:\n",
    "        return series.astype(float) * 1000.0\n",
    "    return series.astype(float)\n",
    "\n",
    "# Bring/scale score columns with resilience to variants (_x1000, _rounded)\n",
    "def _pick_score(base_name: str, fallbacks: list[str]):\n",
    "    for name in [base_name] + fallbacks:\n",
    "        if name in df.columns:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "dse_raw_name = _pick_score(C[\"dse_raw_score\"], [f\"{C['dse_raw_score']}_x1000\", f\"{C['dse_raw_score']}_X1000\",\n",
    "                                               f\"{C['dse_raw_score']}_x1000_rounded\"]) or C[\"dse_raw_score\"]\n",
    "dse_mt_name  = _pick_score(C[\"dse_mt_score\"],  [f\"{C['dse_mt_score']}_x1000\", f\"{C['dse_mt_score']}_X1000\",\n",
    "                                               f\"{C['dse_mt_score']}_x1000_rounded\"]) or C[\"dse_mt_score\"]\n",
    "prod_raw_name = _pick_score(C[\"prod_raw_score\"], [f\"{C['prod_raw_score']}_x1000\", f\"{C['prod_raw_score']}_X1000\",\n",
    "                                                 f\"{C['prod_raw_score']}_x1000_rounded\", \"shadow_ob_score\"]) or C[\"prod_raw_score\"]\n",
    "prod_mt_name  = _pick_score(C[\"prod_mt_score\"],  [f\"{C['prod_mt_score']}_x1000\", f\"{C['prod_mt_score']}_X1000\",\n",
    "                                                 f\"{C['prod_mt_score']}_x1000_rounded\", \"mt_score_prod\"]) or C[\"prod_mt_score\"]\n",
    "\n",
    "# Build scaled numeric columns\n",
    "df[\"dse_raw\"]  = _scale_if_needed(pd.to_numeric(df.get(dse_raw_name, pd.Series(np.nan, index=df.index)), errors=\"coerce\"),\n",
    "                                   CONFIG[\"scaling\"][\"dse_raw_scale_x1000\"]\n",
    "                                  )\n",
    "df[\"dse_mt\"]   = _scale_if_needed(pd.to_numeric(df.get(dse_mt_name,  pd.Series(np.nan, index=df.index)), errors=\"coerce\"),\n",
    "                                   CONFIG[\"scaling\"][\"dse_mt_scale_x1000\"]\n",
    "                                  )\n",
    "df[\"prod_raw\"] = _scale_if_needed(pd.to_numeric(df.get(prod_raw_name, pd.Series(np.nan, index=df.index)), errors=\"coerce\"),\n",
    "                                   CONFIG[\"scaling\"][\"prod_raw_scale_x1000\"]\n",
    "                                  )\n",
    "df[\"prod_mt\"]  = _scale_if_needed(pd.to_numeric(df.get(prod_mt_name,  pd.Series(np.nan, index=df.index)), errors=\"coerce\"),\n",
    "                                   CONFIG[\"scaling\"][\"prod_mt_scale_x1000\"]\n",
    "                                  )\n",
    "\n",
    "# Lifecycle ID (string)\n",
    "lid_col = C[\"lifecycle_id\"] if C[\"lifecycle_id\"] in df.columns else None\n",
    "if lid_col is None:\n",
    "    raise KeyError(\"Expected a 'lifecycle_id' column in the joined dataset.\")\n",
    "df[\"lifecycle_id\"] = df[lid_col].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540b44b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==================================================\n",
    "# Alert flags & margins vs thresholds (per channel)\n",
    "# ==================================================\n",
    "TH = CONFIG[\"thresholds\"]\n",
    "def _get_th_for_channel(ch: str):\n",
    "    if ch in TH: \n",
    "        return TH[ch]\n",
    "    if \"DEFAULT\" in TH:\n",
    "        return TH[\"DEFAULT\"]\n",
    "    # fallback to first\n",
    "    first_key = next(iter(TH))\n",
    "    return TH[first_key]\n",
    "\n",
    "def _alert_flags(row):\n",
    "    th = _get_th_for_channel(row[\"channel\"]) if pd.notna(row[\"channel\"]) else _get_th_for_channel(\"DEFAULT\")\n",
    "    rs_th, mt_th = th[\"RS\"], th[\"MT\"]\n",
    "    is_alert_dse  = (pd.notna(row[\"dse_raw\"])  and row[\"dse_raw\"]  >= rs_th) or (pd.notna(row[\"dse_mt\"])  and row[\"dse_mt\"]  >= mt_th)\n",
    "    is_alert_prod = (pd.notna(row[\"prod_raw\"]) and row[\"prod_raw\"] >= rs_th) or (pd.notna(row[\"prod_mt\"]) and row[\"prod_mt\"] >= mt_th)\n",
    "    raw_margin_dse  = max((row[\"dse_raw\"]  - rs_th) if pd.notna(row[\"dse_raw\"])  else -np.inf,\n",
    "                          (row[\"dse_mt\"]   - mt_th) if pd.notna(row[\"dse_mt\"])   else -np.inf)\n",
    "    raw_margin_prod = max((row[\"prod_raw\"] - rs_th) if pd.notna(row[\"prod_raw\"]) else -np.inf,\n",
    "                          (row[\"prod_mt\"]  - mt_th) if pd.notna(row[\"prod_mt\"])  else -np.inf)\n",
    "    return pd.Series({\n",
    "        \"is_alert_dse\": bool(is_alert_dse),\n",
    "        \"is_alert_prod\": bool(is_alert_prod),\n",
    "        \"margin_dse\": raw_margin_dse if np.isfinite(raw_margin_dse) else np.nan,\n",
    "        \"margin_prod\": raw_margin_prod if np.isfinite(raw_margin_prod) else np.nan\n",
    "    })\n",
    "\n",
    "df = pd.concat([df, df.apply(_alert_flags, axis=1)], axis=1)\n",
    "\n",
    "# Overlap sets within the same row\n",
    "df[\"in_intersection\"] = df[\"is_alert_dse\"] & df[\"is_alert_prod\"]\n",
    "df[\"dse_only_alert\"]  = df[\"is_alert_dse\"] & ~df[\"is_alert_prod\"]\n",
    "df[\"prod_only_alert\"] = ~df[\"is_alert_dse\"] & df[\"is_alert_prod\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025c656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================\n",
    "# Summaries by channel (alerts & overlap pct)\n",
    "# =============================================\n",
    "def _agg_counts(sub):\n",
    "    return pd.DataFrame({\n",
    "        \"events\": sub.size,\n",
    "        \"alerts_dse\": sub[\"is_alert_dse\"].sum(),\n",
    "        \"alerts_prod\": sub[\"is_alert_prod\"].sum(),\n",
    "        \"intersect\": sub[\"in_intersection\"].sum(),\n",
    "        \"dse_only\": sub[\"dse_only_alert\"].sum(),\n",
    "        \"prod_only\": sub[\"prod_only_alert\"].sum()\n",
    "    }, index=[0])\n",
    "\n",
    "by_channel = df.groupby(\"channel\").apply(_agg_counts).reset_index(level=1, drop=True).reset_index()\n",
    "by_channel[\"pct_intersect_of_dse\"]  = np.where(by_channel[\"alerts_dse\"]>0, 100*by_channel[\"intersect\"]/by_channel[\"alerts_dse\"], np.nan)\n",
    "by_channel[\"pct_intersect_of_prod\"] = np.where(by_channel[\"alerts_prod\"]>0, 100*by_channel[\"intersect\"]/by_channel[\"alerts_prod\"], np.nan)\n",
    "\n",
    "display(by_channel)\n",
    "by_channel.to_csv(Path(CONFIG[\"out_dir\"]) / \"summary_by_channel.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4048d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =======================================================\n",
    "# Fraud‑in‑alerts overlap (within alerts only)\n",
    "# =======================================================\n",
    "mask_alerts = df[\"is_alert_dse\"] | df[\"is_alert_prod\"]\n",
    "alerts = df.loc[mask_alerts].copy()\n",
    "alerts[\"fraud_in_dse_alert\"]  = alerts[\"is_alert_dse\"]  & alerts[\"fraud_label\"]\n",
    "alerts[\"fraud_in_prod_alert\"] = alerts[\"is_alert_prod\"] & alerts[\"fraud_label\"]\n",
    "alerts[\"fraud_intersection\"]  = alerts[\"in_intersection\"] & alerts[\"fraud_label\"]\n",
    "alerts[\"fraud_dse_only\"]      = alerts[\"dse_only_alert\"] & alerts[\"fraud_label\"]\n",
    "alerts[\"fraud_prod_only\"]     = alerts[\"prod_only_alert\"] & alerts[\"fraud_label\"]\n",
    "\n",
    "fraud_by_channel = alerts.groupby(\"channel\").agg({\n",
    "    \"fraud_in_dse_alert\": \"sum\",\n",
    "    \"fraud_in_prod_alert\": \"sum\",\n",
    "    \"fraud_intersection\": \"sum\",\n",
    "    \"fraud_dse_only\": \"sum\",\n",
    "    \"fraud_prod_only\": \"sum\",\n",
    "}).reset_index()\n",
    "\n",
    "display(fraud_by_channel)\n",
    "fraud_by_channel.to_csv(Path(CONFIG[\"out_dir\"]) / \"fraud_overlap_by_channel.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea65c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================================\n",
    "# Margin diagnostics for mismatches (how far from thresholds)\n",
    "# ==========================================================\n",
    "dse_only = df.loc[df[\"dse_only_alert\"]].copy()\n",
    "prod_only = df.loc[df[\"prod_only_alert\"]].copy()\n",
    "\n",
    "def _summarise_margins(sub, margin_col):\n",
    "    return sub.groupby(\"channel\")[margin_col].agg([\"count\",\"mean\",\"min\",\"max\"]).reset_index()\n",
    "\n",
    "dse_margins = _summarise_margins(dse_only, \"margin_dse\")\n",
    "prod_margins = _summarise_margins(prod_only, \"margin_prod\")\n",
    "\n",
    "display(dse_margins)\n",
    "display(prod_margins)\n",
    "\n",
    "dse_margins.to_csv(Path(CONFIG[\"out_dir\"]) / \"dse_only_margin_summary.csv\", index=False)\n",
    "prod_margins.to_csv(Path(CONFIG[\"out_dir\"]) / \"prod_only_margin_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2adbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==================================\n",
    "# Hour‑of‑day distributions (UTC)\n",
    "# ==================================\n",
    "def _by_hour(df_in, flag_col, hour_col=\"hour\"):\n",
    "    t = df_in.loc[df_in[flag_col]].copy()\n",
    "    if hour_col not in t.columns:\n",
    "        return pd.DataFrame(columns=[\"hour\",\"count\"]).assign(hour=pd.Series(dtype=float), count=pd.Series(dtype=int))\n",
    "    out = t.groupby(hour_col).size().reset_index(name=\"count\").sort_values(\"hour\")\n",
    "    return out\n",
    "\n",
    "inter_by_hour = _by_hour(df, \"in_intersection\")\n",
    "dse_only_by_hour = _by_hour(df, \"dse_only_alert\")\n",
    "prod_only_by_hour = _by_hour(df, \"prod_only_alert\")\n",
    "\n",
    "display(inter_by_hour)\n",
    "display(dse_only_by_hour)\n",
    "display(prod_only_by_hour)\n",
    "\n",
    "inter_by_hour.to_csv(Path(CONFIG[\"out_dir\"]) / \"intersection_by_hour.csv\", index=False)\n",
    "dse_only_by_hour.to_csv(Path(CONFIG[\"out_dir\"]) / \"dse_only_by_hour.csv\", index=False)\n",
    "prod_only_by_hour.to_csv(Path(CONFIG[\"out_dir\"]) / \"prod_only_by_hour.csv\", index=False)\n",
    "\n",
    "# Fraud‑in‑alerts hours\n",
    "fraud_inter_by_hour = _by_hour(alerts, \"fraud_intersection\")\n",
    "fraud_dse_only_by_hour = _by_hour(alerts, \"fraud_dse_only\")\n",
    "fraud_prod_only_by_hour = _by_hour(alerts, \"fraud_prod_only\")\n",
    "\n",
    "display(fraud_inter_by_hour)\n",
    "display(fraud_dse_only_by_hour)\n",
    "display(fraud_prod_only_by_hour)\n",
    "\n",
    "fraud_inter_by_hour.to_csv(Path(CONFIG[\"out_dir\"]) / \"fraud_intersection_by_hour.csv\", index=False)\n",
    "fraud_dse_only_by_hour.to_csv(Path(CONFIG[\"out_dir\"]) / \"fraud_dse_only_by_hour.csv\", index=False)\n",
    "fraud_prod_only_by_hour.to_csv(Path(CONFIG[\"out_dir\"]) / \"fraud_prod_only_by_hour.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
