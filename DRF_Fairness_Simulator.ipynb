{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a71c04cc",
   "metadata": {},
   "source": [
    "\n",
    "# DRF Fairness — Tiny Simulator (Notebook)\n",
    "This notebook demonstrates **Dominant Resource Fairness (DRF)** inside a single pool (e.g., Batch).\n",
    "You can tweak pool size, executor size, starting allocations, and ceilings, then simulate how the next N executors would be allocated.\n",
    "\n",
    "**What you'll see:**\n",
    "- Final allocation per user (CPU, Memory, dominant share, executor count)\n",
    "- Step-by-step log of who received each executor (with dominant share before/after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d0c66",
   "metadata": {},
   "source": [
    "\n",
    "> **Notes:**  \n",
    "> - Only standard Python + `pandas` is used.\n",
    "> - DRF here operates on **actual CPU and Memory amounts**, not just executor counts.\n",
    "> - This is illustrative; a production scheduler also considers queue order, job priority, and SLOs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2021da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "@dataclass\n",
    "class Pool:\n",
    "    name: str\n",
    "    total_cpu: float          # total vCPU in the pool\n",
    "    total_mem_gb: float       # total GB RAM in the pool\n",
    "    exec_cpu: float           # vCPU per executor\n",
    "    exec_mem_gb: float        # GB RAM per executor\n",
    "\n",
    "@dataclass\n",
    "class UserState:\n",
    "    name: str\n",
    "    cpu: float                # current allocated CPU\n",
    "    mem_gb: float             # current allocated Memory\n",
    "    max_executors: int        # ceiling on number of executors the user can receive\n",
    "    executors: int = field(default=0)  # derived\n",
    "\n",
    "    def can_receive(self, pool: Pool) -> bool:\n",
    "        return self.executors < self.max_executors\n",
    "\n",
    "    def allocate_one(self, pool: Pool):\n",
    "        self.cpu += pool.exec_cpu\n",
    "        self.mem_gb += pool.exec_mem_gb\n",
    "        self.executors += 1\n",
    "\n",
    "def dominant_share(user: UserState, pool: Pool) -> float:\n",
    "    cpu_share = user.cpu / pool.total_cpu if pool.total_cpu else 0.0\n",
    "    mem_share = user.mem_gb / pool.total_mem_gb if pool.total_mem_gb else 0.0\n",
    "    return max(cpu_share, mem_share)\n",
    "\n",
    "def drf_allocate(pool: Pool, users: List[UserState], extra_executors: int, verbose: bool=False) -> Tuple[List[UserState], List[Dict]]:\n",
    "    history = []\n",
    "    for step in range(extra_executors):\n",
    "        eligible = [u for u in users if u.can_receive(pool)]\n",
    "        if not eligible:\n",
    "            if verbose:\n",
    "                print(f\"[step {step}] No eligible users left (ceilings reached).\")\n",
    "            break\n",
    "\n",
    "        shares = [(u, dominant_share(u, pool)) for u in eligible]\n",
    "        shares.sort(key=lambda x: (round(x[1], 12), x[0].name))  # lowest dominant share wins (tie-break by name)\n",
    "        chosen, share_before = shares[0]\n",
    "\n",
    "        chosen.allocate_one(pool)\n",
    "        share_after = dominant_share(chosen, pool)\n",
    "\n",
    "        history.append({\n",
    "            \"step\": step + 1,\n",
    "            \"allocated_to\": chosen.name,\n",
    "            \"dominant_share_before\": round(share_before, 4),\n",
    "            \"dominant_share_after\": round(share_after, 4),\n",
    "            \"total_execs_for_user\": chosen.executors\n",
    "        })\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[step {step+1}] -> {chosen.name}: {share_before:.4f} -> {share_after:.4f} (execs={chosen.executors})\")\n",
    "\n",
    "    return users, history\n",
    "\n",
    "def results_dataframe(users: List[UserState], pool: Pool) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for u in users:\n",
    "        rows.append({\n",
    "            \"user\": u.name,\n",
    "            \"cpu_alloc\": u.cpu,\n",
    "            \"mem_alloc_gb\": u.mem_gb,\n",
    "            \"dominant_share\": round(dominant_share(u, pool), 4),\n",
    "            \"executors\": u.executors,\n",
    "            \"ceiling_execs\": u.max_executors\n",
    "        })\n",
    "    df = pd.DataFrame(rows).sort_values(by=[\"dominant_share\",\"user\"]).reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2408a075",
   "metadata": {},
   "source": [
    "\n",
    "## Configure a scenario\n",
    "Edit the values below and re-run this cell to try different pool sizes, executor sizes, starting allocations, ceilings, and how many new executors to distribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3911de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Pool setup (example: Batch pool) ---\n",
    "pool = Pool(\n",
    "    name=\"batch\",\n",
    "    total_cpu=200,       # total vCPU in the pool\n",
    "    total_mem_gb=800,    # total GB RAM in the pool\n",
    "    exec_cpu=2,          # vCPU per executor\n",
    "    exec_mem_gb=16       # GB RAM per executor\n",
    ")\n",
    "\n",
    "# --- Users starting state ---\n",
    "users = [\n",
    "    # name, starting CPU, starting MEM (GB), ceiling on executors\n",
    "    UserState(name=\"TeamA_CPUheavy\", cpu=60, mem_gb=120, max_executors=30),\n",
    "    UserState(name=\"TeamB_MEMheavy\", cpu=40, mem_gb=400, max_executors=30),\n",
    "    UserState(name=\"TeamC_Light\",    cpu=20, mem_gb=40,  max_executors=30),\n",
    "]\n",
    "\n",
    "# --- How many new executors to allocate using DRF ---\n",
    "extra_executors = 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d744947c",
   "metadata": {},
   "source": [
    "\n",
    "## Run the DRF allocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5971ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "users_after, history = drf_allocate(pool, users, extra_executors=extra_executors, verbose=False)\n",
    "final_df = results_dataframe(users_after, pool)\n",
    "hist_df = pd.DataFrame(history)\n",
    "\n",
    "print(\"=== DRF Final Allocation per User ===\")\n",
    "display(final_df)\n",
    "\n",
    "print(\"\\n=== DRF Allocation Steps (who got each executor) ===\")\n",
    "display(hist_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3cae65",
   "metadata": {},
   "source": [
    "\n",
    "### How to read the results\n",
    "- **dominant_share** is the max of CPU share and Memory share per user (e.g., 0.30 = 30% of that resource in the pool).\n",
    "- The **next executor** is always given to the user with the **lowest** dominant share (subject to their ceiling).\n",
    "- If you increase `extra_executors`, you’ll see users’ dominant shares equalise over time.\n",
    "- Lower a user's `max_executors` to see how **ceilings** cap growth even if they have the lowest share.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}