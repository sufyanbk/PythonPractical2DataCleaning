{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d0cb2f2",
   "metadata": {},
   "source": [
    "# DSE ↔ PROD Alert & Fraud Overlap — **CSV‑Only, Drag‑and‑Drop Notebook**\n",
    "\n",
    "This notebook computes:\n",
    "- Channel summaries for **PROD** (and **DSE** when provided)\n",
    "- **Alert overlap**: intersection, DSE‑only, PROD‑only (+ percentages)\n",
    "- **Fraud overlap** within alerts\n",
    "- **Hour‑of‑day** distributions for intersections and mismatches\n",
    "\n",
    "**How to use**\n",
    "1) Fill the **Spark placeholders** in the next cell with your session code (Feedzai or Spark).\n",
    "2) Set two GCS CSV addresses in the **CONFIG** (DSE is optional).\n",
    "3) Run all cells. All key tables are shown inline and exported as CSVs under `overlap_outputs/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa610a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Spark / Feedzai PLACEHOLDERS\n",
    "# =============================\n",
    "# Replace the two lines below with your real session code.\n",
    "# Example (Feedzai):\n",
    "# from ds_api import feedzai, Server\n",
    "# pulse = Server.connect(address=\"localhost\", port=1899)\n",
    "# feedzai = feedzai(pulse=pulse)\n",
    "# new_spark_params = [\"spark.executor.memory\",\"8G\",\"spark.dynamicAllocation.maxExecutors\",\"100\"]\n",
    "# spark = feedzai.get_spark_session(new_spark_params)\n",
    "\n",
    "# --- Optional local fallback for testing (uncomment if you want to run locally) ---\n",
    "# from pyspark.sql import SparkSession\n",
    "# spark = SparkSession.builder.appName(\"DSE_PROD_Overlap\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "#            CONFIG\n",
    "# =============================\n",
    "from IPython.display import display\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "CONFIG = {\n",
    "    \"paths\": {\n",
    "        \"dse_csv\":  None,\n",
    "        \"prod_csv\": \"gs://bucket/PROD_BASE.csv\",\n",
    "        \"fraud_tags_csv\": None\n",
    "    },\n",
    "    \"csv_read\": {\"delimiter\": \",\", \"header\": True, \"quote\": '\"', \"escape\": \"\\\\\", \"inferSchema\": True},\n",
    "    \"dse_cols\":  {\"lifecycle_id\":\"lifecycle_id\",\"raw_score\":\"fraud_level_true_score\",\"mt_score\":\"money_trick_score\",\n",
    "                  \"fraud_label\":\"fraud_label\",\"event_ts\":\"event_received_at\",\"channel\":\"channel\"},\n",
    "    \"prod_cols\": {\"lifecycle_id\":\"lifecycle_id\",\"raw_score\":\"shadow_ob_score\",\"mt_score\":\"mt_score_prod\",\n",
    "                  \"fraud_label\":\"fraud_label_prod\",\"event_ts\":\"event_received_at\",\"channel\":\"channel\"},\n",
    "    \"fraud_tag_cols\": {\"lifecycle_id\":\"lifecycle_id\",\"fraud_label\":\"fraud_label\"},\n",
    "    \"scaling\": {\"dse_raw_scale\":True,\"dse_mt_scale\":True,\"prod_raw_scale\":True,\"prod_mt_scale\":True},\n",
    "    \"thresholds\": {\"DG\":{\"RS\":980,\"MT\":765},\"FD\":{\"RS\":980,\"MT\":765},\"CMB\":{\"RS\":980,\"MT\":765}},\n",
    "    \"out_dir\": \"overlap_outputs\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da711caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "#            HELPERS\n",
    "# =============================\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "\n",
    "def ensure_outdir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def read_csv(path:str):\n",
    "    if not path:\n",
    "        return None\n",
    "    opts = CONFIG[\"csv_read\"]\n",
    "    df = (spark.read.format(\"csv\")\n",
    "          .option(\"delimiter\", opts[\"delimiter\"])\\\n",
    "          .option(\"header\", str(opts[\"header\"]).lower())\\\n",
    "          .option(\"quote\", opts[\"quote\"])\\\n",
    "          .option(\"escape\", opts[\"escape\"])\\\n",
    "          .option(\"inferSchema\", str(opts.get(\"inferSchema\", True)).lower())\\\n",
    "          .load(path))\n",
    "    return df\n",
    "\n",
    "def coerce_boolean(df, col, out_col):\n",
    "    return (df.withColumn(out_col,\n",
    "            F.when(F.col(col).cast(\"boolean\").isNotNull(), F.col(col).cast(\"boolean\"))\n",
    "             .when(F.col(col).cast(\"int\")==1, True)\n",
    "             .otherwise(False)))\n",
    "\n",
    "def ensure_channel(df, channel_col):\n",
    "    if channel_col in df.columns:\n",
    "        return df\n",
    "    raise ValueError(\"Channel column missing; add your derivation rule in ensure_channel().\")\n",
    "\n",
    "def scale_if_needed(df, col, flag):\n",
    "    if col is None or col not in df.columns:\n",
    "        return df\n",
    "    return df.withColumn(col, (F.col(col) * 1000.0)) if flag else df\n",
    "\n",
    "def build_alert_flag(df, raw_col, mt_col, channel_col, thresholds, out_flag):\n",
    "    if raw_col not in df.columns or mt_col not in df.columns:\n",
    "        return df.withColumn(out_flag, F.lit(False))\n",
    "    cond = None\n",
    "    for ch, thr in thresholds.items():\n",
    "        piece = ((F.col(channel_col)==ch) & (F.col(raw_col)>=thr[\"RS\"]) & (F.col(mt_col)>=thr[\"MT\"]))\n",
    "        cond = piece if cond is None else (cond | piece)\n",
    "    return df.withColumn(out_flag, F.when(cond, True).otherwise(False))\n",
    "\n",
    "def add_hour(df, ts_col, out_col=\"hour\"):\n",
    "    if ts_col not in df.columns:\n",
    "        return df.withColumn(out_col, F.lit(None).cast(\"int\"))\n",
    "    return df.withColumn(out_col, F.hour(F.to_timestamp(F.col(ts_col))))\n",
    "\n",
    "def summarise_counts(df, flag_col, fraud_col, by=[\"channel\"]):\n",
    "    return (df.groupBy(*by)\n",
    "            .agg(F.count(F.lit(1)).alias(\"total\"),\n",
    "                 F.sum(F.when(F.col(flag_col)==True, 1).otherwise(0)).alias(\"alerts\"),\n",
    "                 F.sum(F.when((F.col(flag_col)==True) & (F.col(fraud_col)==True), 1).otherwise(0)).alias(\"fraud_in_alerts\")))\n",
    "\n",
    "def show_and_export(df, csv_name):\n",
    "    out_dir = CONFIG[\"out_dir\"]\n",
    "    ensure_outdir(out_dir)\n",
    "    pdf = df.toPandas()\n",
    "    display(pdf.head(10))\n",
    "    import os\n",
    "    pdf.to_csv(os.path.join(out_dir, csv_name), index=False)\n",
    "    print(f\"Saved: {os.path.join(out_dir, csv_name)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2316c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "#              LOAD\n",
    "# =============================\n",
    "paths = CONFIG[\"paths\"]\n",
    "dse  = read_csv(paths[\"dse_csv\"])   if paths[\"dse_csv\"]  else None\n",
    "prod = read_csv(paths[\"prod_csv\"])  if paths[\"prod_csv\"] else None\n",
    "tags = read_csv(paths[\"fraud_tags_csv\"]) if paths[\"fraud_tags_csv\"] else None\n",
    "\n",
    "print(\"Loaded -> DSE:\", dse is not None, \"| PROD:\", prod is not None, \"| TAGS:\", tags is not None)\n",
    "if prod is None:\n",
    "    raise RuntimeError(\"PROD CSV is required to proceed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd791bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "#           PREPARE DSE\n",
    "# =============================\n",
    "dse_cols = CONFIG[\"dse_cols\"]\n",
    "if dse is not None:\n",
    "    dse = (dse\n",
    "           .withColumn(dse_cols[\"lifecycle_id\"], F.col(dse_cols[\"lifecycle_id\"]).cast(\"string\"))\n",
    "           .withColumnRenamed(dse_cols[\"lifecycle_id\"], \"lifecycle_id\"))\n",
    "    dse = scale_if_needed(dse, dse_cols[\"raw_score\"], CONFIG[\"scaling\"][\"dse_raw_scale\"])\n",
    "    dse = scale_if_needed(dse, dse_cols[\"mt_score\"],  CONFIG[\"scaling\"][\"dse_mt_scale\"])\n",
    "    dse = ensure_channel(dse, dse_cols[\"channel\"])\n",
    "    if dse_cols[\"channel\"] != \"channel\":\n",
    "        dse = dse.withColumnRenamed(dse_cols[\"channel\"], \"channel\")\n",
    "    if dse_cols[\"fraud_label\"] in dse.columns:\n",
    "        dse = coerce_boolean(dse, dse_cols[\"fraud_label\"], \"fraud_label_dse\")\n",
    "    else:\n",
    "        dse = dse.withColumn(\"fraud_label_dse\", F.lit(False))\n",
    "    dse = build_alert_flag(dse, dse_cols[\"raw_score\"], dse_cols[\"mt_score\"], \"channel\", CONFIG[\"thresholds\"], \"is_alert_dse\")\n",
    "    dse = add_hour(dse, dse_cols[\"event_ts\"], \"hour\")\n",
    "    dse = dse.select(\"lifecycle_id\",\"channel\",\"hour\",\n",
    "                     F.col(dse_cols[\"raw_score\"]).alias(\"raw_score_dse\"),\n",
    "                     F.col(dse_cols[\"mt_score\"]).alias(\"mt_score_dse\") if dse_cols[\"mt_score\"] in dse.columns else F.lit(None).alias(\"mt_score_dse\"),\n",
    "                     \"is_alert_dse\",\"fraud_label_dse\")\n",
    "    print(\"DSE preview:\")\n",
    "    show_and_export(dse.limit(1000), \"preview_dse.csv\")\n",
    "else:\n",
    "    print(\"DSE not provided — continuing with PROD only.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "#          PREPARE PROD\n",
    "# =============================\n",
    "prod_cols = CONFIG[\"prod_cols\"]\n",
    "prod = (prod\n",
    "        .withColumn(prod_cols[\"lifecycle_id\"], F.col(prod_cols[\"lifecycle_id\"]).cast(\"string\"))\n",
    "        .withColumnRenamed(prod_cols[\"lifecycle_id\"], \"lifecycle_id\"))\n",
    "prod = scale_if_needed(prod, prod_cols[\"raw_score\"], CONFIG[\"scaling\"][\"prod_raw_scale\"])\n",
    "prod = scale_if_needed(prod, prod_cols[\"mt_score\"],  CONFIG[\"scaling\"][\"prod_mt_scale\"])\n",
    "prod = ensure_channel(prod, prod_cols[\"channel\"])\n",
    "if prod_cols[\"channel\"] != \"channel\":\n",
    "    prod = prod.withColumnRenamed(prod_cols[\"channel\"], \"channel\")\n",
    "\n",
    "# Attach/normalize fraud label\n",
    "if prod_cols[\"fraud_label\"] in prod.columns:\n",
    "    prod = coerce_boolean(prod, prod_cols[\"fraud_label\"], \"fraud_label_prod\")\n",
    "elif tags is not None:\n",
    "    tag_cols = CONFIG[\"fraud_tag_cols\"]\n",
    "    tags_use = (tags\n",
    "                .select(F.col(tag_cols[\"lifecycle_id\"]).cast(\"string\").alias(\"lifecycle_id\"),\n",
    "                        F.col(tag_cols[\"fraud_label\"]).alias(\"fraud_label_join\")))\n",
    "    prod = (prod.join(tags_use, \"lifecycle_id\", \"left\")\n",
    "               .withColumn(\"fraud_label_prod\",\n",
    "                           F.when(F.col(\"fraud_label_join\").cast(\"boolean\").isNotNull(), F.col(\"fraud_label_join\").cast(\"boolean\"))\n",
    "                            .when(F.col(\"fraud_label_join\").cast(\"int\")==1, True)\n",
    "                            .otherwise(False))\n",
    "               .drop(\"fraud_label_join\"))\n",
    "else:\n",
    "    prod = prod.withColumn(\"fraud_label_prod\", F.lit(False))\n",
    "\n",
    "prod = build_alert_flag(prod, prod_cols[\"raw_score\"], prod_cols[\"mt_score\"], \"channel\", CONFIG[\"thresholds\"], \"is_alert_prod\")\n",
    "prod = add_hour(prod, prod_cols[\"event_ts\"], \"hour\")\n",
    "prod = prod.select(\"lifecycle_id\",\"channel\",\"hour\",\n",
    "                   F.col(prod_cols[\"raw_score\"]).alias(\"raw_score_prod\"),\n",
    "                   F.col(prod_cols[\"mt_score\"]).alias(\"mt_score_prod\") if prod_cols[\"mt_score\"] in prod.columns else F.lit(None).alias(\"mt_score_prod\"),\n",
    "                   \"is_alert_prod\",\"fraud_label_prod\")\n",
    "print(\"PROD preview:\")\n",
    "show_and_export(prod.limit(1000), \"preview_prod.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4afe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "#       CHANNEL SUMMARIES\n",
    "# =============================\n",
    "prod_summary = (prod.groupBy(\"channel\")\n",
    "                    .agg(F.count(\"*\").alias(\"total\"),\n",
    "                         F.sum(F.when(F.col(\"is_alert_prod\")==True, 1).otherwise(0)).alias(\"alerts\"),\n",
    "                         F.sum(F.when((F.col(\"is_alert_prod\")==True) & (F.col(\"fraud_label_prod\")==True), 1).otherwise(0)).alias(\"fraud_in_alerts\")))\n",
    "print(\"PROD summary by channel:\")\n",
    "show_and_export(prod_summary.orderBy(\"channel\"), \"prod_summary_by_channel.csv\")\n",
    "\n",
    "if 'dse' in globals() and dse is not None:\n",
    "    dse_summary = (dse.groupBy(\"channel\")\n",
    "                      .agg(F.count(\"*\").alias(\"total\"),\n",
    "                           F.sum(F.when(F.col(\"is_alert_dse\")==True, 1).otherwise(0)).alias(\"alerts\"),\n",
    "                           F.sum(F.when((F.col(\"is_alert_dse\")==True) & (F.col(\"fraud_label_dse\")==True), 1).otherwise(0)).alias(\"fraud_in_alerts\")))\n",
    "    print(\"DSE summary by channel:\")\n",
    "    show_and_export(dse_summary.orderBy(\"channel\"), \"dse_summary_by_channel.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbedaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "#         ALERT OVERLAPS\n",
    "# =============================\n",
    "if 'dse' in globals() and dse is not None:\n",
    "    dse_alerts  = dse.filter(F.col(\"is_alert_dse\")==True).select(\"lifecycle_id\",\"channel\",\"hour\")\n",
    "    prod_alerts = prod.filter(F.col(\"is_alert_prod\")==True).select(\"lifecycle_id\",\"channel\",\"hour\")\n",
    "\n",
    "    inter = dse_alerts.join(prod_alerts, \"lifecycle_id\", \"inner\").withColumnRenamed(\"channel\",\"channel_dse\")\n",
    "    dse_only  = dse_alerts.join(prod_alerts.select(\"lifecycle_id\"), \"lifecycle_id\", \"left_anti\")\n",
    "    prod_only = prod_alerts.join(dse_alerts.select(\"lifecycle_id\"), \"lifecycle_id\", \"left_anti\")\n",
    "\n",
    "    dse_alert_counts  = dse_alerts.groupBy(\"channel\").agg(F.count(\"*\").alias(\"dse_alerts\"))\n",
    "    prod_alert_counts = prod_alerts.groupBy(\"channel\").agg(F.count(\"*\").alias(\"prod_alerts\"))\n",
    "    inter_counts = inter.groupBy(\"channel_dse\").agg(F.count(\"*\").alias(\"intersection\"))\n",
    "\n",
    "    overlap_pct = (inter_counts\n",
    "        .join(dse_alert_counts, inter_counts[\"channel_dse\"]==dse_alert_counts[\"channel\"], \"left\")\n",
    "        .join(prod_alert_counts, inter_counts[\"channel_dse\"]==prod_alert_counts[\"channel\"], \"left\")\n",
    "        .select(F.col(\"channel_dse\").alias(\"channel\"),\n",
    "                \"intersection\",\n",
    "                (F.col(\"intersection\")/F.col(\"dse_alerts\")).alias(\"overlap_vs_dse\"),\n",
    "                (F.col(\"intersection\")/F.col(\"prod_alerts\")).alias(\"overlap_vs_prod\"))\n",
    "        .orderBy(\"channel\"))\n",
    "\n",
    "    print(\"Overlap % by channel:\")\n",
    "    show_and_export(overlap_pct, \"overlap_percentages.csv\")\n",
    "    print(\"DSE‑only alerts by channel:\")\n",
    "    show_and_export(dse_only.groupBy(\"channel\").agg(F.count(\"*\").alias(\"dse_only_alerts\")).orderBy(\"channel\"),\n",
    "                    \"dse_only_alerts.csv\")\n",
    "    print(\"PROD‑only alerts by channel:\")\n",
    "    show_and_export(prod_only.groupBy(\"channel\").agg(F.count(\"*\").alias(\"prod_only_alerts\")).orderBy(\"channel\"),\n",
    "                    \"prod_only_alerts.csv\")\n",
    "else:\n",
    "    print(\"DSE not provided — overlaps will compute once DSE CSV is set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f87ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "#   FRAUD OVERLAP (IN ALERTS)\n",
    "# =============================\n",
    "if 'dse' in globals() and dse is not None:\n",
    "    dse_alerts_fraud  = dse.filter((F.col(\"is_alert_dse\")==True) & (F.col(\"fraud_label_dse\")==True)).select(\"lifecycle_id\",\"channel\")\n",
    "    prod_alerts_fraud = prod.filter((F.col(\"is_alert_prod\")==True) & (F.col(\"fraud_label_prod\")==True)).select(\"lifecycle_id\",\"channel\")\n",
    "\n",
    "    fraud_inter = (dse_alerts_fraud.join(prod_alerts_fraud, \"lifecycle_id\", \"inner\")\n",
    "                   .withColumnRenamed(\"channel\",\"channel_dse\")\n",
    "                   .groupBy(\"channel_dse\").agg(F.count(\"*\").alias(\"fraud_intersection\")).orderBy(\"channel_dse\"))\n",
    "    print(\"Fraud intersection (alerts) by channel:\")\n",
    "    show_and_export(fraud_inter, \"fraud_intersection_by_channel.csv\")\n",
    "\n",
    "    dse_only_fraud = (dse_alerts_fraud.join(prod_alerts_fraud.select(\"lifecycle_id\"), \"lifecycle_id\", \"left_anti\")\n",
    "                      .groupBy(\"channel\").agg(F.count(\"*\").alias(\"dse_only_fraud_alerts\")).orderBy(\"channel\"))\n",
    "    print(\"DSE-only fraud-in-alerts by channel:\")\n",
    "    show_and_export(dse_only_fraud, \"dse_only_fraud_alerts.csv\")\n",
    "\n",
    "    prod_only_fraud = (prod_alerts_fraud.join(dse_alerts_fraud.select(\"lifecycle_id\"), \"lifecycle_id\", \"left_anti\")\n",
    "                       .groupBy(\"channel\").agg(F.count(\"*\").alias(\"prod_only_fraud_alerts\")).orderBy(\"channel\"))\n",
    "    print(\"PROD-only fraud-in-alerts by channel:\")\n",
    "    show_and_export(prod_only_fraud, \"prod_only_fraud_alerts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f484b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "#    HOUR-OF-DAY DISTRIBUTIONS\n",
    "# =============================\n",
    "if 'dse' in globals() and dse is not None:\n",
    "    inter_hours   = inter.groupBy(\"hour\").agg(F.count(\"*\").alias(\"alerts_intersection_by_hour\")).orderBy(\"hour\")\n",
    "    dse_only_hours  = dse_only.groupBy(\"hour\").agg(F.count(\"*\").alias(\"dse_only_by_hour\")).orderBy(\"hour\")\n",
    "    prod_only_hours = prod_only.groupBy(\"hour\").agg(F.count(\"*\").alias(\"prod_only_by_hour\")).orderBy(\"hour\")\n",
    "    print(\"Alerts intersection by hour:\")\n",
    "    show_and_export(inter_hours, \"alerts_intersection_by_hour.csv\")\n",
    "    print(\"DSE-only alerts by hour:\")\n",
    "    show_and_export(dse_only_hours, \"dse_only_by_hour.csv\")\n",
    "    print(\"PROD-only alerts by hour:\")\n",
    "    show_and_export(prod_only_hours, \"prod_only_by_hour.csv\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}