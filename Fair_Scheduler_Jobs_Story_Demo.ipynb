{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce38d91",
   "metadata": {},
   "source": [
    "\n",
    "# Fair Scheduler Story — Jobs View (Heaviest vs Medium vs Light Eval)\n",
    "\n",
    "This notebook **tells a story** using **jobs** (not teams):\n",
    "- **Heaviest job** (big model plan)\n",
    "- **Medium job**\n",
    "- **Light model evaluation job**\n",
    "\n",
    "We compare a naive **BEFORE** scheduler (round‑robin) with an **AFTER** scheduler using **DRF (Dominant Resource Fairness)**.\n",
    "\n",
    "You’ll get:\n",
    "- **Step‑by‑step** allocation logs for BEFORE and AFTER, with a **reason** for each step.\n",
    "- **Final allocations** for each job.\n",
    "- **Visuals:** final dominant shares and how they evolve as we allocate more executors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a88558",
   "metadata": {},
   "source": [
    "\n",
    "## Notes\n",
    "- We model a single pool (e.g., **Batch**) with fixed **CPU** and **Memory** capacity.\n",
    "- Each **executor** consumes a fixed amount of CPU & Memory.\n",
    "- Jobs start with some allocations already (representing work already in progress).\n",
    "- We then distribute the **next N executors**.\n",
    "- **BEFORE = Round‑robin:** rotates blindly, ignores real usage.\n",
    "\n",
    "- **AFTER = DRF:** gives the next executor to the job with the **lowest dominant share** (its bigger share of CPU or Mem).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a7e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "@dataclass\n",
    "class Pool:\n",
    "    name: str\n",
    "    total_cpu: float\n",
    "    total_mem_gb: float\n",
    "    exec_cpu: float\n",
    "    exec_mem_gb: float\n",
    "\n",
    "@dataclass\n",
    "class JobState:\n",
    "    name: str\n",
    "    cpu: float\n",
    "    mem_gb: float\n",
    "    max_executors: int\n",
    "    executors: int = field(default=0)\n",
    "\n",
    "    def can_receive(self) -> bool:\n",
    "        return self.executors < self.max_executors\n",
    "\n",
    "    def allocate_one(self, pool: Pool):\n",
    "        self.cpu += pool.exec_cpu\n",
    "        self.mem_gb += pool.exec_mem_gb\n",
    "        self.executors += 1\n",
    "\n",
    "def dominant_share(job: JobState, pool: Pool) -> float:\n",
    "    cpu_share = job.cpu / pool.total_cpu if pool.total_cpu else 0.0\n",
    "    mem_share = job.mem_gb / pool.total_mem_gb if pool.total_mem_gb else 0.0\n",
    "    return max(cpu_share, mem_share)\n",
    "\n",
    "def shares_snapshot(jobs: List[JobState], pool: Pool) -> Dict[str, Dict[str, float]]:\n",
    "    snap = {}\n",
    "    for j in jobs:\n",
    "        cpu_share = j.cpu / pool.total_cpu if pool.total_cpu else 0.0\n",
    "        mem_share = j.mem_gb / pool.total_mem_gb if pool.total_mem_gb else 0.0\n",
    "        snap[j.name] = {\n",
    "            \"cpu_share\": cpu_share,\n",
    "            \"mem_share\": mem_share,\n",
    "            \"dominant_share\": max(cpu_share, mem_share)\n",
    "        }\n",
    "    return snap\n",
    "\n",
    "def round_robin_allocate(pool: Pool, jobs: List[JobState], extra_executors: int):\n",
    "    history = []\n",
    "    idx = 0\n",
    "    steps = 0\n",
    "    while steps < extra_executors:\n",
    "        j = jobs[idx % len(jobs)]\n",
    "        idx += 1\n",
    "        if not j.can_receive():\n",
    "            continue\n",
    "        pre = shares_snapshot(jobs, pool)\n",
    "        pre_dom = pre[j.name]['dominant_share']\n",
    "        j.allocate_one(pool)\n",
    "        post_dom = dominant_share(j, pool)\n",
    "        steps += 1\n",
    "        history.append({\n",
    "            \"step\": steps,\n",
    "            \"allocated_to\": j.name,\n",
    "            \"reason\": \"round-robin (fixed order, ignores real usage)\",\n",
    "            \"dominant_share_before\": round(pre_dom, 4),\n",
    "            \"dominant_share_after\": round(post_dom, 4),\n",
    "            \"total_execs_for_job\": j.executors\n",
    "        })\n",
    "    return jobs, history\n",
    "\n",
    "def drf_allocate(pool: Pool, jobs: List[JobState], extra_executors: int):\n",
    "    history = []\n",
    "    for step in range(1, extra_executors+1):\n",
    "        eligible = [j for j in jobs if j.can_receive()]\n",
    "        if not eligible: break\n",
    "        snaps = shares_snapshot(jobs, pool)\n",
    "        eligible.sort(key=lambda j: (round(snaps[j.name]['dominant_share'], 12), j.name))\n",
    "        chosen = eligible[0]\n",
    "        pre_dom = snaps[chosen.name]['dominant_share']\n",
    "        shares_reason = \", \".join([f\"{n}: {snaps[n]['dominant_share']:.3f}\" for n in sorted(snaps.keys())])\n",
    "        chosen.allocate_one(pool)\n",
    "        post_dom = dominant_share(chosen, pool)\n",
    "        history.append({\n",
    "            \"step\": step,\n",
    "            \"allocated_to\": chosen.name,\n",
    "            \"reason\": f\"lowest dominant share wins → [{shares_reason}]\",\n",
    "            \"dominant_share_before\": round(pre_dom, 4),\n",
    "            \"dominant_share_after\": round(post_dom, 4),\n",
    "            \"total_execs_for_job\": chosen.executors\n",
    "        })\n",
    "    return jobs, history\n",
    "\n",
    "def summarize(jobs: List[JobState], pool: Pool) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for j in jobs:\n",
    "        cpu_share = j.cpu / pool.total_cpu if pool.total_cpu else 0.0\n",
    "        mem_share = j.mem_gb / pool.total_mem_gb if pool.total_mem_gb else 0.0\n",
    "        rows.append({\n",
    "            \"job\": j.name,\n",
    "            \"cpu_alloc\": j.cpu,\n",
    "            \"mem_alloc_gb\": j.mem_gb,\n",
    "            \"cpu_share\": round(cpu_share, 4),\n",
    "            \"mem_share\": round(mem_share, 4),\n",
    "            \"dominant_share\": round(max(cpu_share, mem_share), 4),\n",
    "            \"executors_added\": j.executors\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(by=[\"dominant_share\",\"job\"]).reset_index(drop=True)\n",
    "\n",
    "def clone_jobs(jobs: List[JobState]) -> List[JobState]:\n",
    "    return [JobState(j.name, j.cpu, j.mem_gb, j.max_executors, j.executors) for j in jobs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b35a65f",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Scenario (you can tweak these numbers)\n",
    "- **Pool:** 200 vCPU, 800 GB RAM. Each executor uses **2 vCPU** and **16 GB RAM**.\n",
    "- **Jobs:**  \n",
    "  - **Heaviest_Job** — big model plan (starts high on CPU and Mem: 60 vCPU, 240 GB).  \n",
    "  - **Medium_Job** — medium feature/eval run (40 vCPU, 240 GB).  \n",
    "  - **Light_Eval_Job** — quick model evaluation (20 vCPU, 40 GB).  \n",
    "- **Ceilings:** max 30 new executors for any job (demo).  \n",
    "- **We will distribute:** next **15 executors**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88187ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pool = Pool(name=\"Batch\", total_cpu=200, total_mem_gb=800, exec_cpu=2, exec_mem_gb=16)\n",
    "\n",
    "jobs_seed = [\n",
    "    JobState(name=\"Heaviest_Job\", cpu=60, mem_gb=240, max_executors=30),\n",
    "    JobState(name=\"Medium_Job\",   cpu=40, mem_gb=240, max_executors=30),\n",
    "    JobState(name=\"Light_Eval_Job\", cpu=20, mem_gb=40, max_executors=30),\n",
    "]\n",
    "\n",
    "extra_executors = 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26bbc79",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Run BEFORE (Round‑Robin) and AFTER (DRF)\n",
    "We clone the same starting state, run each scheduler, and capture a detailed **step-by-step** log with **reasons**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c57e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jobs_rr = clone_jobs(jobs_seed)\n",
    "jobs_drf = clone_jobs(jobs_seed)\n",
    "\n",
    "jobs_rr_after, rr_history = round_robin_allocate(pool, jobs_rr, extra_executors=extra_executors)\n",
    "jobs_drf_after, drf_history = drf_allocate(pool, jobs_drf, extra_executors=extra_executors)\n",
    "\n",
    "rr_df = pd.DataFrame(rr_history)\n",
    "drf_df = pd.DataFrame(drf_history)\n",
    "\n",
    "print(\"=== BEFORE: Round‑Robin step log ===\")\n",
    "display(rr_df)\n",
    "\n",
    "print(\"\\n=== AFTER: DRF step log ===\")\n",
    "display(drf_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0426a57",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Final Allocations (Before vs After)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a13ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sum_rr = summarize(jobs_rr_after, pool)\n",
    "sum_drf = summarize(jobs_drf_after, pool)\n",
    "\n",
    "print(\"=== BEFORE: Round‑Robin final allocation ===\")\n",
    "display(sum_rr)\n",
    "\n",
    "print(\"\\n=== AFTER: DRF final allocation ===\")\n",
    "display(sum_drf)\n",
    "\n",
    "diff = sum_drf.set_index(\"job\")[[\"cpu_alloc\",\"mem_alloc_gb\",\"dominant_share\"]].subtract(\n",
    "       sum_rr.set_index(\"job\")[[\"cpu_alloc\",\"mem_alloc_gb\",\"dominant_share\"]], fill_value=0).reset_index()\n",
    "\n",
    "print(\"\\n=== Difference (AFTER - BEFORE) ===\")\n",
    "display(diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a14f7c7",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Visual — Final Dominant Share (BEFORE: Round‑Robin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a1ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(sum_rr[\"job\"], sum_rr[\"dominant_share\"])\n",
    "plt.title(\"Final Dominant Share — BEFORE (Round‑Robin)\")\n",
    "plt.xlabel(\"Job\")\n",
    "plt.ylabel(\"Dominant Share (0.0–1.0)\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b1b7ef",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Visual — Final Dominant Share (AFTER: DRF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6472ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(sum_drf[\"job\"], sum_drf[\"dominant_share\"])\n",
    "plt.title(\"Final Dominant Share — AFTER (DRF)\")\n",
    "plt.xlabel(\"Job\")\n",
    "plt.ylabel(\"Dominant Share (0.0–1.0)\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6735cea",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Visual — DRF: Dominant Share Over Allocation Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ca2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drf_timeline(pool: Pool, jobs_seed: List[JobState], extra: int):\n",
    "    jobs = clone_jobs(jobs_seed)\n",
    "    timeline = {\"step\":[0]}\n",
    "    snap0 = shares_snapshot(jobs, pool)\n",
    "    for j in jobs:\n",
    "        timeline[j.name] = [snap0[j.name][\"dominant_share\"]]\n",
    "    for step in range(1, extra+1):\n",
    "        eligible = [j for j in jobs if j.can_receive()]\n",
    "        if not eligible: break\n",
    "        snaps = shares_snapshot(jobs, pool)\n",
    "        eligible.sort(key=lambda j: (round(snaps[j.name]['dominant_share'], 12), j.name))\n",
    "        chosen = eligible[0]\n",
    "        chosen.allocate_one(pool)\n",
    "        timeline[\"step\"].append(step)\n",
    "        snaps2 = shares_snapshot(jobs, pool)\n",
    "        for j in jobs:\n",
    "            timeline[j.name].append(snaps2[j.name][\"dominant_share\"])\n",
    "    return pd.DataFrame(timeline)\n",
    "\n",
    "timeline_drf = drf_timeline(pool, jobs_seed, extra_executors)\n",
    "plt.figure(figsize=(6,4))\n",
    "for col in [c for c in timeline_drf.columns if c != \"step\"]:\n",
    "    plt.plot(timeline_drf[\"step\"], timeline_drf[col], label=col)\n",
    "plt.title(\"AFTER (DRF) — Dominant Share Over Steps\")\n",
    "plt.xlabel(\"Allocation Step\")\n",
    "plt.ylabel(\"Dominant Share (0.0–1.0)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b872c8c3",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Visual — Round‑Robin: Dominant Share Over Allocation Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d1c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rr_timeline(pool: Pool, jobs_seed: List[JobState], extra: int):\n",
    "    jobs = clone_jobs(jobs_seed)\n",
    "    timeline = {\"step\":[0]}\n",
    "    snap0 = shares_snapshot(jobs, pool)\n",
    "    for j in jobs:\n",
    "        timeline[j.name] = [snap0[j.name][\"dominant_share\"]]\n",
    "    idx = 0\n",
    "    steps = 0\n",
    "    while steps < extra:\n",
    "        j = jobs[idx % len(jobs)]\n",
    "        idx += 1\n",
    "        if not j.can_receive():\n",
    "            continue\n",
    "        j.allocate_one(pool)\n",
    "        steps += 1\n",
    "        timeline[\"step\"].append(steps)\n",
    "        snap = shares_snapshot(jobs, pool)\n",
    "        for job in jobs:\n",
    "            timeline[job.name].append(snap[job.name][\"dominant_share\"])\n",
    "    return pd.DataFrame(timeline)\n",
    "\n",
    "timeline_rr = rr_timeline(pool, jobs_seed, extra_executors)\n",
    "plt.figure(figsize=(6,4))\n",
    "for col in [c for c in timeline_rr.columns if c != \"step\"]:\n",
    "    plt.plot(timeline_rr[\"step\"], timeline_rr[col], label=col)\n",
    "plt.title(\"BEFORE (Round‑Robin) — Dominant Share Over Steps\")\n",
    "plt.xlabel(\"Allocation Step\")\n",
    "plt.ylabel(\"Dominant Share (0.0–1.0)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c1fef",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Story Wrap‑Up (What to say)\n",
    "- **Before:** Round‑robin blindly rotates, so the **Heaviest Job** might keep getting capacity even when the **Light Eval Job** is far behind. Unfair & unpredictable.\n",
    "\n",
    "- **After:** DRF always allocates the next executor to the job with the **lowest dominant share** (furthest behind). Shares converge → **no job hogs the pool**.\n",
    "\n",
    "- **Why each step happens:** The DRF step log shows each job’s share before allocation; the **lowest number wins** that step.\n",
    "\n",
    "- **In production:** We’d also enforce **executor ceilings** per job and **per‑user concurrency caps** to prevent flooding, plus pool isolation for Interactive vs Batch.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}